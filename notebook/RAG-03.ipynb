{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e7bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "######### CONFLUENCE & CHUNKING #########\n",
    "#########################################\n",
    "\n",
    "from langchain.document_loaders import ConfluenceLoader\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai \n",
    "load_dotenv()\n",
    "#\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d84422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "# Ingest Confluence Page \n",
    "#########################################\n",
    "from langchain.document_loaders import ConfluenceLoader\n",
    "\n",
    "CONFLUENCE_API_TOKEN = \"NDc5MjIzMjE5MjUzOheP7HLxuLUv2dVQrNF0Uxx9Xj50\"\n",
    "CONFLUENCE_BASE_URL =  \"https://wiki.softtech.com.tr/\"\n",
    "CONFLUENCE_SPACE_KEY = \"SDO\"\n",
    "\n",
    "loader = ConfluenceLoader(\n",
    "    url=CONFLUENCE_BASE_URL, token=CONFLUENCE_API_TOKEN, cloud=False\n",
    ")\n",
    "\n",
    "docs = loader.load(space_key=CONFLUENCE_SPACE_KEY, include_attachments=True )\n",
    "\n",
    "# Look at one page content and its metadata\n",
    "print(\"Content: \\n ------- \\n\" + docs[-1].page_content)\n",
    "print(\"Metadatas: \\n ------- \\n\" + str(docs[-1].metadata))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Split chunks \n",
    "##################\n",
    "def my_custom_splitter(docs):\n",
    "    # Markdown\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Title 1\"),\n",
    "        (\"##\", \"Subtitle-title 1\"), \n",
    "        (\"###\", \"Subtitle-title 2\"),\n",
    "    ]\n",
    "\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "\n",
    "    # Split based on markdown and add original metadata\n",
    "    md_docs = []\n",
    "    for doc in docs:\n",
    "        md_doc = markdown_splitter.split_text(doc.page_content)\n",
    "        for i in range(len(md_doc)):\n",
    "            md_doc[i].metadata = md_doc[i].metadata | doc.metadata\n",
    "        md_docs.extend(md_doc)\n",
    "\n",
    "    # RecursiveTextSplitter\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    # Chunk size big enough\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=20,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    splitted_docs = splitter.split_documents(md_docs)\n",
    "    return splitted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fdebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = my_custom_splitter(docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804396f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(chunks):\n",
    "    print(\n",
    "        str('\\n' + '='*50 + '\\n').join(\n",
    "            [\n",
    "                chunk.page_content + '\\n' +'-'*50 + '\\n' + str(chunk.metadata) \n",
    "                for chunk in chunks\n",
    "            ]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks size\n",
    "print(\"Number of cnk: \" + str(len(chunks)))\n",
    "\n",
    "pretty_print(chunks[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea52f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    " ##############################\n",
    " #### COLLECTION - Vector DB \n",
    " ##############################\n",
    "\n",
    "from langchain.vectorstores import Milvus\n",
    "from langchain.embeddings import OpenAIEmbeddings \n",
    "from pymilvus import connections, utility, FieldSchema, Collection, CollectionSchema, DataType\n",
    "\n",
    "\n",
    "COLLECTION_NAME = \"SDO\" # os.getenv(\"COLLECTION_NAME\")\n",
    "EMBEDDING_MODEL = os.getenv(\"OPENAI_ENGINE\")\n",
    "MILVUS_HOST = \"23.236.50.189\"\n",
    "MILVUS_PORT = \"19530\"\n",
    "DIMENSION = 1536\n",
    " \n",
    "\n",
    "connections.connect(host=MILVUS_HOST, port=MILVUS_PORT) \n",
    "if connections.has_connection:\n",
    "    print(f\"Connection estabilished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b415c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "### CREATE COLLECTION & INDEX ########\n",
    "######################################\n",
    "if not utility.has_collection(COLLECTION_NAME):\n",
    "        print(f\"Creating {COLLECTION_NAME} collection\")\n",
    "         # 1. define fields\n",
    "        fields = [\n",
    "            FieldSchema(name='pk', dtype=DataType.INT64, descrition='pk', is_primary=True, auto_id=False),\n",
    "            FieldSchema(name='id', dtype=DataType.INT32, descrition='page id', is_primary=False, auto_id=False),\n",
    "            FieldSchema(name='title', dtype=DataType.VARCHAR, descrition='titles', max_length=5000),\n",
    "            FieldSchema(name='page_content', dtype=DataType.VARCHAR, descrition='page_content', max_length=5000),\n",
    "            FieldSchema(name='source', dtype=DataType.VARCHAR, descrition='sources', max_length=5000),\n",
    "            FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, descrition='embedding vectors', dim=DIMENSION)\n",
    "        ]\n",
    "         # 2. enable dynamic schema in schema definition\n",
    "        schema = CollectionSchema(fields=fields, description='wiki softtech devops pages')\n",
    "        # 3. reference the schema in a collection\n",
    "        collection = Collection(name=COLLECTION_NAME, schema=schema, consistency_level=\"Strong\")\n",
    "        # 4. index the vector field and load the collection\n",
    "        INDEX_PARAM = {\n",
    "            'metric_type': 'L2',\n",
    "            'index_type': \"HNSW\",\n",
    "            'params': {'M': 8, 'efConstruction': 64}\n",
    "        } \n",
    "\n",
    "        collection.create_index(field_name=\"embedding\", index_params=INDEX_PARAM)\n",
    "\n",
    "         # 5. load the collection\n",
    "        collection.load()  \n",
    "\n",
    "        print(f\"{COLLECTION_NAME} collection loaded\") \n",
    "\n",
    "else:\n",
    "    collection = Collection(f\"{COLLECTION_NAME}\")\n",
    "    collection.load() \n",
    "    print(f\"{COLLECTION_NAME} collection reloaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a6a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Creating {COLLECTION_NAME} collection\")\n",
    "collection.flush()\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### INSERT Chunks ########\n",
    "##########################\n",
    "  \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    " \n",
    "\n",
    "def insert_chunks(chunks, embed, collection):\n",
    "    try:\n",
    "        cnk = chunks[:4]\n",
    "        BATCH_SIZE = 2\n",
    "        batch_data = [[], [], [], [], [], []]\n",
    "        start = 0\n",
    "        end = min(BATCH_SIZE, len(cnk))  # İlk BATCH_SIZE'ı hesapla.\n",
    "        count = 0\n",
    "        while start < len(cnk):\n",
    "            for i in tqdm(range(start, end)): \n",
    "                count += 1\n",
    "                batch_data[0].append(np.int64(count))\n",
    "                batch_data[1].append(np.int32(cnk[i].metadata['id']))\n",
    "                batch_data[2].append(cnk[i].metadata['title'])\n",
    "                batch_data[3].append(cnk[i].page_content)\n",
    "                batch_data[4].append(cnk[i].metadata['source']) \n",
    "         \n",
    "            embeddings = embed([text for text in batch_data[3]]) # liste olarak gönder\n",
    "            batch_data[5].extend(embeddings)\n",
    "\n",
    "            collection.insert(batch_data)\n",
    "\n",
    "            batch_data = [[], [], [], [], [], []]\n",
    "\n",
    "            start = end\n",
    "            end = min(start + BATCH_SIZE, len(cnk))\n",
    "            print(\"End of batch, next start index: \", start)\n",
    "      \n",
    "            \n",
    "            print(\"Waiting for 6 seconds...\")\n",
    "            time.sleep(6)\n",
    "           \n",
    "\n",
    "    except openai.RateLimitError as e:\n",
    "        print(\"Rate limit exceeded. Retrying after 9 seconds...\")\n",
    "        time.sleep(9)\n",
    "        return insert_chunks(chunks, embed, collection)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
    "client = AzureOpenAI( \n",
    "    api_version=\"2023-03-15-preview\" , \n",
    "    api_key=\"08430e02fcde44b299549ee5c650cd76\",\n",
    "    azure_endpoint=\"https://softtech-openai-ynt.openai.azure.com\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7482576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(texts):\n",
    "    return [client.embeddings.create(input=[text], model=\"text-embedding-ada-002\").data[0].embedding for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_chunks(chunks, generate_embeddings, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5150b-3701-44e7-9b40-85217307dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.flush()\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5392d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Query\n",
    "##################\n",
    "import textwrap\n",
    "\n",
    "QUERY_PARAM = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"ef\": 64},\n",
    "}\n",
    "\n",
    "\n",
    "def search(queries):\n",
    "    top_k = 5\n",
    "    if type(queries) != list:\n",
    "        queries = [queries]\n",
    "    res = collection.search(generate_embeddings(queries), anns_field='embedding', param=QUERY_PARAM, limit=top_k,\n",
    "                            output_fields=['page_content'])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8cf24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search(\"Sonar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74caef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc05ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31de72d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0775e485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ffa112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb4d395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba42b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afbc47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500b96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2dbb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89cb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e914248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
